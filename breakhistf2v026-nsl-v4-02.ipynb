{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "4745\n",
      "2.0.0\n",
      "1582\n",
      "WARNING:tensorflow:Output output_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to output_1.\n",
      "Epoch 1/100\n",
      "297/297 [==============================] - 424s 1s/step - loss: 1.9666 - sparse_categorical_crossentropy: 1.6115 - sparse_categorical_accuracy: 0.4844 - adversarial_loss: 1.7754 - val_loss: 0.0000e+00 - val_sparse_categorical_crossentropy: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00 - val_adversarial_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "297/297 [==============================] - 280s 943ms/step - loss: 1.7696 - sparse_categorical_crossentropy: 1.4314 - sparse_categorical_accuracy: 0.5135 - adversarial_loss: 1.6935 - val_loss: 1.7286 - val_sparse_categorical_crossentropy: 1.3767 - val_sparse_categorical_accuracy: 0.5183 - val_adversarial_loss: 1.6622\n",
      "Epoch 3/100\n",
      "297/297 [==============================] - 271s 911ms/step - loss: 1.6679 - sparse_categorical_crossentropy: 1.3336 - sparse_categorical_accuracy: 0.5322 - adversarial_loss: 1.6721 - val_loss: 1.6802 - val_sparse_categorical_crossentropy: 1.3266 - val_sparse_categorical_accuracy: 0.5278 - val_adversarial_loss: 1.6733\n",
      "Epoch 4/100\n",
      "297/297 [==============================] - 267s 900ms/step - loss: 1.6136 - sparse_categorical_crossentropy: 1.2805 - sparse_categorical_accuracy: 0.5491 - adversarial_loss: 1.6678 - val_loss: 1.6080 - val_sparse_categorical_crossentropy: 1.2606 - val_sparse_categorical_accuracy: 0.5607 - val_adversarial_loss: 1.6463\n",
      "Epoch 5/100\n",
      "297/297 [==============================] - 264s 890ms/step - loss: 1.5584 - sparse_categorical_crossentropy: 1.2314 - sparse_categorical_accuracy: 0.5658 - adversarial_loss: 1.6382 - val_loss: 1.5592 - val_sparse_categorical_crossentropy: 1.2113 - val_sparse_categorical_accuracy: 0.5664 - val_adversarial_loss: 1.6518\n",
      "Epoch 6/100\n",
      "297/297 [==============================] - 272s 917ms/step - loss: 1.5111 - sparse_categorical_crossentropy: 1.1862 - sparse_categorical_accuracy: 0.5742 - adversarial_loss: 1.6280 - val_loss: 1.5359 - val_sparse_categorical_crossentropy: 1.1855 - val_sparse_categorical_accuracy: 0.5708 - val_adversarial_loss: 1.6655\n",
      "Epoch 7/100\n",
      "297/297 [==============================] - 257s 865ms/step - loss: 1.4717 - sparse_categorical_crossentropy: 1.1462 - sparse_categorical_accuracy: 0.5941 - adversarial_loss: 1.6308 - val_loss: 1.5028 - val_sparse_categorical_crossentropy: 1.1490 - val_sparse_categorical_accuracy: 0.5752 - val_adversarial_loss: 1.6847\n",
      "Epoch 8/100\n",
      "297/297 [==============================] - 252s 849ms/step - loss: 1.4406 - sparse_categorical_crossentropy: 1.1158 - sparse_categorical_accuracy: 0.5979 - adversarial_loss: 1.6286 - val_loss: 1.4890 - val_sparse_categorical_crossentropy: 1.1376 - val_sparse_categorical_accuracy: 0.5733 - val_adversarial_loss: 1.6734\n",
      "Epoch 9/100\n",
      "297/297 [==============================] - 254s 857ms/step - loss: 1.4078 - sparse_categorical_crossentropy: 1.0849 - sparse_categorical_accuracy: 0.6030 - adversarial_loss: 1.6175 - val_loss: 1.4666 - val_sparse_categorical_crossentropy: 1.1065 - val_sparse_categorical_accuracy: 0.5917 - val_adversarial_loss: 1.7179\n",
      "Epoch 10/100\n",
      "297/297 [==============================] - 267s 900ms/step - loss: 1.3813 - sparse_categorical_crossentropy: 1.0624 - sparse_categorical_accuracy: 0.6132 - adversarial_loss: 1.5975 - val_loss: 1.4366 - val_sparse_categorical_crossentropy: 1.0804 - val_sparse_categorical_accuracy: 0.6068 - val_adversarial_loss: 1.7003\n",
      "Epoch 11/100\n",
      "297/297 [==============================] - 272s 916ms/step - loss: 1.3438 - sparse_categorical_crossentropy: 1.0277 - sparse_categorical_accuracy: 0.6269 - adversarial_loss: 1.5862 - val_loss: 1.4317 - val_sparse_categorical_crossentropy: 1.0695 - val_sparse_categorical_accuracy: 0.5898 - val_adversarial_loss: 1.7303\n",
      "Epoch 12/100\n",
      "297/297 [==============================] - 258s 868ms/step - loss: 1.3125 - sparse_categorical_crossentropy: 0.9973 - sparse_categorical_accuracy: 0.6269 - adversarial_loss: 1.5792 - val_loss: 1.4188 - val_sparse_categorical_crossentropy: 1.0522 - val_sparse_categorical_accuracy: 0.6005 - val_adversarial_loss: 1.7532\n",
      "Epoch 13/100\n",
      "297/297 [==============================] - 259s 874ms/step - loss: 1.2965 - sparse_categorical_crossentropy: 0.9812 - sparse_categorical_accuracy: 0.6354 - adversarial_loss: 1.5782 - val_loss: 1.4221 - val_sparse_categorical_crossentropy: 1.0504 - val_sparse_categorical_accuracy: 0.6005 - val_adversarial_loss: 1.7783\n",
      "Epoch 14/100\n",
      "297/297 [==============================] - 252s 850ms/step - loss: 1.2521 - sparse_categorical_crossentropy: 0.9415 - sparse_categorical_accuracy: 0.6496 - adversarial_loss: 1.5577 - val_loss: 1.3980 - val_sparse_categorical_crossentropy: 1.0273 - val_sparse_categorical_accuracy: 0.6157 - val_adversarial_loss: 1.7750\n",
      "Epoch 15/100\n",
      "297/297 [==============================] - 248s 834ms/step - loss: 1.2245 - sparse_categorical_crossentropy: 0.9131 - sparse_categorical_accuracy: 0.6522 - adversarial_loss: 1.5586 - val_loss: 1.3734 - val_sparse_categorical_crossentropy: 0.9958 - val_sparse_categorical_accuracy: 0.6233 - val_adversarial_loss: 1.8110\n",
      "Epoch 16/100\n",
      "297/297 [==============================] - 258s 869ms/step - loss: 1.1922 - sparse_categorical_crossentropy: 0.8830 - sparse_categorical_accuracy: 0.6709 - adversarial_loss: 1.5533 - val_loss: 1.3518 - val_sparse_categorical_crossentropy: 0.9754 - val_sparse_categorical_accuracy: 0.6359 - val_adversarial_loss: 1.8058\n",
      "Epoch 17/100\n",
      "297/297 [==============================] - 251s 846ms/step - loss: 1.1715 - sparse_categorical_crossentropy: 0.8625 - sparse_categorical_accuracy: 0.6842 - adversarial_loss: 1.5493 - val_loss: 1.3503 - val_sparse_categorical_crossentropy: 0.9673 - val_sparse_categorical_accuracy: 0.6403 - val_adversarial_loss: 1.8391\n",
      "Epoch 18/100\n",
      "297/297 [==============================] - 259s 872ms/step - loss: 1.1494 - sparse_categorical_crossentropy: 0.8439 - sparse_categorical_accuracy: 0.6829 - adversarial_loss: 1.5309 - val_loss: 1.3726 - val_sparse_categorical_crossentropy: 0.9736 - val_sparse_categorical_accuracy: 0.6340 - val_adversarial_loss: 1.9173\n",
      "Epoch 19/100\n",
      "297/297 [==============================] - 244s 820ms/step - loss: 1.1277 - sparse_categorical_crossentropy: 0.8186 - sparse_categorical_accuracy: 0.6913 - adversarial_loss: 1.5482 - val_loss: 1.3489 - val_sparse_categorical_crossentropy: 0.9534 - val_sparse_categorical_accuracy: 0.6378 - val_adversarial_loss: 1.9018\n",
      "Epoch 20/100\n",
      "297/297 [==============================] - 245s 824ms/step - loss: 1.1084 - sparse_categorical_crossentropy: 0.7988 - sparse_categorical_accuracy: 0.7004 - adversarial_loss: 1.5521 - val_loss: 1.3842 - val_sparse_categorical_crossentropy: 0.9779 - val_sparse_categorical_accuracy: 0.6308 - val_adversarial_loss: 1.9535\n",
      "Epoch 21/100\n",
      "297/297 [==============================] - 236s 793ms/step - loss: 1.0790 - sparse_categorical_crossentropy: 0.7761 - sparse_categorical_accuracy: 0.7091 - adversarial_loss: 1.5200 - val_loss: 1.3333 - val_sparse_categorical_crossentropy: 0.9240 - val_sparse_categorical_accuracy: 0.6441 - val_adversarial_loss: 1.9717\n",
      "Epoch 22/100\n",
      "297/297 [==============================] - 227s 763ms/step - loss: 1.0620 - sparse_categorical_crossentropy: 0.7598 - sparse_categorical_accuracy: 0.7179 - adversarial_loss: 1.5142 - val_loss: 1.3390 - val_sparse_categorical_crossentropy: 0.9333 - val_sparse_categorical_accuracy: 0.6568 - val_adversarial_loss: 1.9536\n",
      "Epoch 23/100\n",
      "297/297 [==============================] - 252s 849ms/step - loss: 1.0502 - sparse_categorical_crossentropy: 0.7462 - sparse_categorical_accuracy: 0.7183 - adversarial_loss: 1.5234 - val_loss: 1.3289 - val_sparse_categorical_crossentropy: 0.9236 - val_sparse_categorical_accuracy: 0.6441 - val_adversarial_loss: 1.9514\n",
      "Epoch 24/100\n",
      "297/297 [==============================] - 230s 773ms/step - loss: 1.0320 - sparse_categorical_crossentropy: 0.7311 - sparse_categorical_accuracy: 0.7255 - adversarial_loss: 1.5129 - val_loss: 1.3532 - val_sparse_categorical_crossentropy: 0.9515 - val_sparse_categorical_accuracy: 0.6416 - val_adversarial_loss: 1.9325\n",
      "Epoch 25/100\n",
      "297/297 [==============================] - 254s 855ms/step - loss: 1.0221 - sparse_categorical_crossentropy: 0.7219 - sparse_categorical_accuracy: 0.7326 - adversarial_loss: 1.5061 - val_loss: 1.3251 - val_sparse_categorical_crossentropy: 0.9131 - val_sparse_categorical_accuracy: 0.6549 - val_adversarial_loss: 1.9859\n",
      "Epoch 26/100\n",
      "297/297 [==============================] - 252s 848ms/step - loss: 0.9896 - sparse_categorical_crossentropy: 0.6950 - sparse_categorical_accuracy: 0.7412 - adversarial_loss: 1.4787 - val_loss: 1.2999 - val_sparse_categorical_crossentropy: 0.8807 - val_sparse_categorical_accuracy: 0.6593 - val_adversarial_loss: 2.0229\n",
      "Epoch 27/100\n",
      "297/297 [==============================] - 261s 877ms/step - loss: 0.9714 - sparse_categorical_crossentropy: 0.6759 - sparse_categorical_accuracy: 0.7514 - adversarial_loss: 1.4795 - val_loss: 1.2983 - val_sparse_categorical_crossentropy: 0.8849 - val_sparse_categorical_accuracy: 0.6625 - val_adversarial_loss: 1.9942\n",
      "Epoch 28/100\n",
      "297/297 [==============================] - 246s 829ms/step - loss: 0.9567 - sparse_categorical_crossentropy: 0.6650 - sparse_categorical_accuracy: 0.7523 - adversarial_loss: 1.4607 - val_loss: 1.3567 - val_sparse_categorical_crossentropy: 0.9353 - val_sparse_categorical_accuracy: 0.6416 - val_adversarial_loss: 2.0305\n",
      "Epoch 29/100\n",
      "297/297 [==============================] - 246s 827ms/step - loss: 0.9387 - sparse_categorical_crossentropy: 0.6498 - sparse_categorical_accuracy: 0.7583 - adversarial_loss: 1.4483 - val_loss: 1.3364 - val_sparse_categorical_crossentropy: 0.9084 - val_sparse_categorical_accuracy: 0.6523 - val_adversarial_loss: 2.0645\n",
      "Epoch 30/100\n",
      "297/297 [==============================] - 247s 830ms/step - loss: 0.9188 - sparse_categorical_crossentropy: 0.6331 - sparse_categorical_accuracy: 0.7614 - adversarial_loss: 1.4295 - val_loss: 1.3470 - val_sparse_categorical_crossentropy: 0.9126 - val_sparse_categorical_accuracy: 0.6694 - val_adversarial_loss: 2.0966\n",
      "Epoch 31/100\n",
      "297/297 [==============================] - 246s 829ms/step - loss: 0.9120 - sparse_categorical_crossentropy: 0.6249 - sparse_categorical_accuracy: 0.7693 - adversarial_loss: 1.4398 - val_loss: 1.3184 - val_sparse_categorical_crossentropy: 0.8847 - val_sparse_categorical_accuracy: 0.6681 - val_adversarial_loss: 2.0945\n",
      "Epoch 32/100\n",
      "297/297 [==============================] - 264s 890ms/step - loss: 0.8879 - sparse_categorical_crossentropy: 0.6057 - sparse_categorical_accuracy: 0.7766 - adversarial_loss: 1.4147 - val_loss: 1.3143 - val_sparse_categorical_crossentropy: 0.8859 - val_sparse_categorical_accuracy: 0.6833 - val_adversarial_loss: 2.0683\n",
      "Epoch 33/100\n",
      "297/297 [==============================] - 264s 888ms/step - loss: 0.8696 - sparse_categorical_crossentropy: 0.5892 - sparse_categorical_accuracy: 0.7805 - adversarial_loss: 1.4041 - val_loss: 1.3094 - val_sparse_categorical_crossentropy: 0.8779 - val_sparse_categorical_accuracy: 0.6776 - val_adversarial_loss: 2.0840\n",
      "Epoch 34/100\n",
      "297/297 [==============================] - 249s 839ms/step - loss: 0.8596 - sparse_categorical_crossentropy: 0.5779 - sparse_categorical_accuracy: 0.7876 - adversarial_loss: 1.4148 - val_loss: 1.3582 - val_sparse_categorical_crossentropy: 0.9114 - val_sparse_categorical_accuracy: 0.6536 - val_adversarial_loss: 2.1579\n",
      "Epoch 35/100\n",
      "297/297 [==============================] - 260s 874ms/step - loss: 0.8525 - sparse_categorical_crossentropy: 0.5749 - sparse_categorical_accuracy: 0.7857 - adversarial_loss: 1.3901 - val_loss: 1.3099 - val_sparse_categorical_crossentropy: 0.8721 - val_sparse_categorical_accuracy: 0.6795 - val_adversarial_loss: 2.1153\n",
      "Epoch 36/100\n",
      "297/297 [==============================] - 247s 832ms/step - loss: 0.8431 - sparse_categorical_crossentropy: 0.5635 - sparse_categorical_accuracy: 0.7886 - adversarial_loss: 1.4036 - val_loss: 1.3284 - val_sparse_categorical_crossentropy: 0.8838 - val_sparse_categorical_accuracy: 0.6738 - val_adversarial_loss: 2.1482\n",
      "Epoch 37/100\n",
      "297/297 [==============================] - 232s 780ms/step - loss: 0.8276 - sparse_categorical_crossentropy: 0.5525 - sparse_categorical_accuracy: 0.7962 - adversarial_loss: 1.3811 - val_loss: 1.3187 - val_sparse_categorical_crossentropy: 0.8688 - val_sparse_categorical_accuracy: 0.6858 - val_adversarial_loss: 2.1753\n",
      "Epoch 38/100\n",
      "297/297 [==============================] - 233s 785ms/step - loss: 0.8302 - sparse_categorical_crossentropy: 0.5534 - sparse_categorical_accuracy: 0.7941 - adversarial_loss: 1.3867 - val_loss: 1.3601 - val_sparse_categorical_crossentropy: 0.9080 - val_sparse_categorical_accuracy: 0.6738 - val_adversarial_loss: 2.1840\n",
      "Epoch 39/100\n",
      "297/297 [==============================] - 246s 828ms/step - loss: 0.8045 - sparse_categorical_crossentropy: 0.5313 - sparse_categorical_accuracy: 0.8040 - adversarial_loss: 1.3700 - val_loss: 1.3507 - val_sparse_categorical_crossentropy: 0.8991 - val_sparse_categorical_accuracy: 0.6783 - val_adversarial_loss: 2.1822\n",
      "Epoch 40/100\n",
      "297/297 [==============================] - 256s 862ms/step - loss: 0.7931 - sparse_categorical_crossentropy: 0.5232 - sparse_categorical_accuracy: 0.8067 - adversarial_loss: 1.3531 - val_loss: 1.3528 - val_sparse_categorical_crossentropy: 0.9026 - val_sparse_categorical_accuracy: 0.6764 - val_adversarial_loss: 2.1747\n",
      "Epoch 41/100\n",
      "297/297 [==============================] - 266s 894ms/step - loss: 0.7939 - sparse_categorical_crossentropy: 0.5261 - sparse_categorical_accuracy: 0.8015 - adversarial_loss: 1.3433 - val_loss: 1.3784 - val_sparse_categorical_crossentropy: 0.9131 - val_sparse_categorical_accuracy: 0.6827 - val_adversarial_loss: 2.2493\n",
      "Epoch 42/100\n",
      "297/297 [==============================] - 250s 840ms/step - loss: 0.7803 - sparse_categorical_crossentropy: 0.5103 - sparse_categorical_accuracy: 0.8071 - adversarial_loss: 1.3525 - val_loss: 1.3323 - val_sparse_categorical_crossentropy: 0.8692 - val_sparse_categorical_accuracy: 0.6839 - val_adversarial_loss: 2.2404\n",
      "Epoch 43/100\n",
      "297/297 [==============================] - 258s 867ms/step - loss: 0.7553 - sparse_categorical_crossentropy: 0.4920 - sparse_categorical_accuracy: 0.8231 - adversarial_loss: 1.3215 - val_loss: 1.3744 - val_sparse_categorical_crossentropy: 0.9074 - val_sparse_categorical_accuracy: 0.6802 - val_adversarial_loss: 2.2578\n",
      "Epoch 44/100\n",
      "297/297 [==============================] - 251s 845ms/step - loss: 0.7598 - sparse_categorical_crossentropy: 0.4950 - sparse_categorical_accuracy: 0.8185 - adversarial_loss: 1.3254 - val_loss: 1.3842 - val_sparse_categorical_crossentropy: 0.9153 - val_sparse_categorical_accuracy: 0.6827 - val_adversarial_loss: 2.2670\n",
      "Epoch 45/100\n",
      "297/297 [==============================] - 263s 885ms/step - loss: 0.7583 - sparse_categorical_crossentropy: 0.4946 - sparse_categorical_accuracy: 0.8193 - adversarial_loss: 1.3213 - val_loss: 1.3851 - val_sparse_categorical_crossentropy: 0.9155 - val_sparse_categorical_accuracy: 0.6827 - val_adversarial_loss: 2.2699\n",
      "Epoch 46/100\n",
      "297/297 [==============================] - 243s 817ms/step - loss: 0.7478 - sparse_categorical_crossentropy: 0.4835 - sparse_categorical_accuracy: 0.8223 - adversarial_loss: 1.3229 - val_loss: 1.4156 - val_sparse_categorical_crossentropy: 0.9257 - val_sparse_categorical_accuracy: 0.6770 - val_adversarial_loss: 2.3699\n",
      "Epoch 47/100\n",
      "297/297 [==============================] - 251s 844ms/step - loss: 0.7288 - sparse_categorical_crossentropy: 0.4662 - sparse_categorical_accuracy: 0.8303 - adversarial_loss: 1.3147 - val_loss: 1.4215 - val_sparse_categorical_crossentropy: 0.9290 - val_sparse_categorical_accuracy: 0.6675 - val_adversarial_loss: 2.3829\n",
      "Epoch 48/100\n",
      "297/297 [==============================] - 257s 864ms/step - loss: 0.7349 - sparse_categorical_crossentropy: 0.4735 - sparse_categorical_accuracy: 0.8280 - adversarial_loss: 1.3088 - val_loss: 1.4118 - val_sparse_categorical_crossentropy: 0.9353 - val_sparse_categorical_accuracy: 0.6820 - val_adversarial_loss: 2.3034\n",
      "Epoch 49/100\n",
      "297/297 [==============================] - 279s 939ms/step - loss: 0.7192 - sparse_categorical_crossentropy: 0.4599 - sparse_categorical_accuracy: 0.8330 - adversarial_loss: 1.2971 - val_loss: 1.4650 - val_sparse_categorical_crossentropy: 0.9534 - val_sparse_categorical_accuracy: 0.6719 - val_adversarial_loss: 2.4753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "297/297 [==============================] - 281s 947ms/step - loss: 0.7145 - sparse_categorical_crossentropy: 0.4581 - sparse_categorical_accuracy: 0.8288 - adversarial_loss: 1.2827 - val_loss: 1.3794 - val_sparse_categorical_crossentropy: 0.9006 - val_sparse_categorical_accuracy: 0.6858 - val_adversarial_loss: 2.3163\n",
      "Epoch 51/100\n",
      "297/297 [==============================] - 271s 912ms/step - loss: 0.7180 - sparse_categorical_crossentropy: 0.4602 - sparse_categorical_accuracy: 0.8289 - adversarial_loss: 1.2881 - val_loss: 1.4222 - val_sparse_categorical_crossentropy: 0.9471 - val_sparse_categorical_accuracy: 0.6650 - val_adversarial_loss: 2.2954\n",
      "Epoch 52/100\n",
      "297/297 [==============================] - 286s 962ms/step - loss: 0.6985 - sparse_categorical_crossentropy: 0.4457 - sparse_categorical_accuracy: 0.8358 - adversarial_loss: 1.2692 - val_loss: 1.4528 - val_sparse_categorical_crossentropy: 0.9515 - val_sparse_categorical_accuracy: 0.6713 - val_adversarial_loss: 2.4248\n",
      "Epoch 53/100\n",
      "297/297 [==============================] - 273s 920ms/step - loss: 0.6884 - sparse_categorical_crossentropy: 0.4372 - sparse_categorical_accuracy: 0.8362 - adversarial_loss: 1.2581 - val_loss: 1.4267 - val_sparse_categorical_crossentropy: 0.9294 - val_sparse_categorical_accuracy: 0.6814 - val_adversarial_loss: 2.4064\n",
      "Epoch 54/100\n",
      "297/297 [==============================] - 276s 930ms/step - loss: 0.6641 - sparse_categorical_crossentropy: 0.4184 - sparse_categorical_accuracy: 0.8437 - adversarial_loss: 1.2282 - val_loss: 1.4196 - val_sparse_categorical_crossentropy: 0.9331 - val_sparse_categorical_accuracy: 0.6833 - val_adversarial_loss: 2.3526\n",
      "Epoch 55/100\n",
      "297/297 [==============================] - 270s 908ms/step - loss: 0.6567 - sparse_categorical_crossentropy: 0.4138 - sparse_categorical_accuracy: 0.8498 - adversarial_loss: 1.2180 - val_loss: 1.3878 - val_sparse_categorical_crossentropy: 0.8881 - val_sparse_categorical_accuracy: 0.6972 - val_adversarial_loss: 2.4204\n",
      "Epoch 56/100\n",
      "297/297 [==============================] - 262s 882ms/step - loss: 0.6657 - sparse_categorical_crossentropy: 0.4173 - sparse_categorical_accuracy: 0.8491 - adversarial_loss: 1.2443 - val_loss: 1.3557 - val_sparse_categorical_crossentropy: 0.8726 - val_sparse_categorical_accuracy: 0.6966 - val_adversarial_loss: 2.3391\n",
      "Epoch 57/100\n",
      "297/297 [==============================] - 253s 852ms/step - loss: 0.6555 - sparse_categorical_crossentropy: 0.4092 - sparse_categorical_accuracy: 0.8513 - adversarial_loss: 1.2322 - val_loss: 1.4487 - val_sparse_categorical_crossentropy: 0.9518 - val_sparse_categorical_accuracy: 0.6941 - val_adversarial_loss: 2.4032\n",
      "Epoch 58/100\n",
      "297/297 [==============================] - 244s 821ms/step - loss: 0.6544 - sparse_categorical_crossentropy: 0.4081 - sparse_categorical_accuracy: 0.8498 - adversarial_loss: 1.2317 - val_loss: 1.4461 - val_sparse_categorical_crossentropy: 0.9414 - val_sparse_categorical_accuracy: 0.6726 - val_adversarial_loss: 2.4421\n",
      "Epoch 59/100\n",
      "297/297 [==============================] - 236s 796ms/step - loss: 0.6622 - sparse_categorical_crossentropy: 0.4159 - sparse_categorical_accuracy: 0.8476 - adversarial_loss: 1.2328 - val_loss: 1.4382 - val_sparse_categorical_crossentropy: 0.9264 - val_sparse_categorical_accuracy: 0.6972 - val_adversarial_loss: 2.4781\n",
      "Epoch 60/100\n",
      "297/297 [==============================] - 244s 822ms/step - loss: 0.6142 - sparse_categorical_crossentropy: 0.3804 - sparse_categorical_accuracy: 0.8645 - adversarial_loss: 1.1695 - val_loss: 1.4508 - val_sparse_categorical_crossentropy: 0.9335 - val_sparse_categorical_accuracy: 0.6871 - val_adversarial_loss: 2.5050\n",
      "Epoch 61/100\n",
      "297/297 [==============================] - 248s 835ms/step - loss: 0.6236 - sparse_categorical_crossentropy: 0.3812 - sparse_categorical_accuracy: 0.8587 - adversarial_loss: 1.2094 - val_loss: 1.5045 - val_sparse_categorical_crossentropy: 0.9762 - val_sparse_categorical_accuracy: 0.6738 - val_adversarial_loss: 2.5569\n",
      "Epoch 62/100\n",
      "297/297 [==============================] - 243s 819ms/step - loss: 0.6146 - sparse_categorical_crossentropy: 0.3779 - sparse_categorical_accuracy: 0.8622 - adversarial_loss: 1.1828 - val_loss: 1.4680 - val_sparse_categorical_crossentropy: 0.9542 - val_sparse_categorical_accuracy: 0.6877 - val_adversarial_loss: 2.4862\n",
      "Epoch 63/100\n",
      "297/297 [==============================] - 246s 828ms/step - loss: 0.6066 - sparse_categorical_crossentropy: 0.3680 - sparse_categorical_accuracy: 0.8644 - adversarial_loss: 1.1933 - val_loss: 1.4432 - val_sparse_categorical_crossentropy: 0.9460 - val_sparse_categorical_accuracy: 0.6808 - val_adversarial_loss: 2.4048\n",
      "Epoch 64/100\n",
      "297/297 [==============================] - 253s 854ms/step - loss: 0.6258 - sparse_categorical_crossentropy: 0.3864 - sparse_categorical_accuracy: 0.8585 - adversarial_loss: 1.1964 - val_loss: 1.5051 - val_sparse_categorical_crossentropy: 0.9913 - val_sparse_categorical_accuracy: 0.6726 - val_adversarial_loss: 2.4840\n",
      "Epoch 65/100\n",
      "297/297 [==============================] - 247s 832ms/step - loss: 0.6141 - sparse_categorical_crossentropy: 0.3771 - sparse_categorical_accuracy: 0.8631 - adversarial_loss: 1.1818 - val_loss: 1.4332 - val_sparse_categorical_crossentropy: 0.9279 - val_sparse_categorical_accuracy: 0.6858 - val_adversarial_loss: 2.4464\n",
      "Epoch 66/100\n",
      "297/297 [==============================] - 249s 839ms/step - loss: 0.5963 - sparse_categorical_crossentropy: 0.3645 - sparse_categorical_accuracy: 0.8673 - adversarial_loss: 1.1607 - val_loss: 1.5340 - val_sparse_categorical_crossentropy: 0.9952 - val_sparse_categorical_accuracy: 0.6865 - val_adversarial_loss: 2.6075\n",
      "Epoch 67/100\n",
      "297/297 [==============================] - 265s 894ms/step - loss: 0.6001 - sparse_categorical_crossentropy: 0.3681 - sparse_categorical_accuracy: 0.8691 - adversarial_loss: 1.1606 - val_loss: 1.4390 - val_sparse_categorical_crossentropy: 0.9388 - val_sparse_categorical_accuracy: 0.6896 - val_adversarial_loss: 2.4199\n",
      "Epoch 68/100\n",
      "297/297 [==============================] - 256s 863ms/step - loss: 0.5801 - sparse_categorical_crossentropy: 0.3469 - sparse_categorical_accuracy: 0.8739 - adversarial_loss: 1.1639 - val_loss: 1.4273 - val_sparse_categorical_crossentropy: 0.9312 - val_sparse_categorical_accuracy: 0.6890 - val_adversarial_loss: 2.4004\n",
      "Epoch 69/100\n",
      "297/297 [==============================] - 263s 887ms/step - loss: 0.5858 - sparse_categorical_crossentropy: 0.3514 - sparse_categorical_accuracy: 0.8702 - adversarial_loss: 1.1709 - val_loss: 1.5838 - val_sparse_categorical_crossentropy: 1.0295 - val_sparse_categorical_accuracy: 0.6681 - val_adversarial_loss: 2.6823\n",
      "Epoch 70/100\n",
      "297/297 [==============================] - 251s 845ms/step - loss: 0.5722 - sparse_categorical_crossentropy: 0.3412 - sparse_categorical_accuracy: 0.8765 - adversarial_loss: 1.1555 - val_loss: 1.5852 - val_sparse_categorical_crossentropy: 1.0329 - val_sparse_categorical_accuracy: 0.6643 - val_adversarial_loss: 2.6723\n",
      "Epoch 71/100\n",
      "297/297 [==============================] - 251s 846ms/step - loss: 0.5987 - sparse_categorical_crossentropy: 0.3617 - sparse_categorical_accuracy: 0.8697 - adversarial_loss: 1.1854 - val_loss: 1.5622 - val_sparse_categorical_crossentropy: 1.0265 - val_sparse_categorical_accuracy: 0.6618 - val_adversarial_loss: 2.5905\n",
      "Epoch 72/100\n",
      "297/297 [==============================] - 258s 868ms/step - loss: 0.5963 - sparse_categorical_crossentropy: 0.3648 - sparse_categorical_accuracy: 0.8652 - adversarial_loss: 1.1570 - val_loss: 1.6091 - val_sparse_categorical_crossentropy: 1.0617 - val_sparse_categorical_accuracy: 0.6820 - val_adversarial_loss: 2.6467\n",
      "Epoch 73/100\n",
      "297/297 [==============================] - 266s 895ms/step - loss: 0.5519 - sparse_categorical_crossentropy: 0.3299 - sparse_categorical_accuracy: 0.8807 - adversarial_loss: 1.1086 - val_loss: 1.6169 - val_sparse_categorical_crossentropy: 1.0551 - val_sparse_categorical_accuracy: 0.6764 - val_adversarial_loss: 2.7178\n",
      "Epoch 74/100\n",
      "297/297 [==============================] - 257s 867ms/step - loss: 0.5504 - sparse_categorical_crossentropy: 0.3262 - sparse_categorical_accuracy: 0.8822 - adversarial_loss: 1.1201 - val_loss: 1.5571 - val_sparse_categorical_crossentropy: 1.0198 - val_sparse_categorical_accuracy: 0.6770 - val_adversarial_loss: 2.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "297/297 [==============================] - 235s 792ms/step - loss: 0.5580 - sparse_categorical_crossentropy: 0.3321 - sparse_categorical_accuracy: 0.8800 - adversarial_loss: 1.1269 - val_loss: 1.6872 - val_sparse_categorical_crossentropy: 1.1153 - val_sparse_categorical_accuracy: 0.6593 - val_adversarial_loss: 2.7650\n",
      "Epoch 76/100\n",
      "297/297 [==============================] - 259s 873ms/step - loss: 0.5823 - sparse_categorical_crossentropy: 0.3539 - sparse_categorical_accuracy: 0.8715 - adversarial_loss: 1.1397 - val_loss: 1.6339 - val_sparse_categorical_crossentropy: 1.0840 - val_sparse_categorical_accuracy: 0.6688 - val_adversarial_loss: 2.6581\n",
      "Epoch 77/100\n",
      "297/297 [==============================] - 250s 842ms/step - loss: 0.5589 - sparse_categorical_crossentropy: 0.3341 - sparse_categorical_accuracy: 0.8801 - adversarial_loss: 1.1217 - val_loss: 1.5821 - val_sparse_categorical_crossentropy: 1.0381 - val_sparse_categorical_accuracy: 0.6719 - val_adversarial_loss: 2.6309\n",
      "Epoch 78/100\n",
      "297/297 [==============================] - 255s 858ms/step - loss: 0.5530 - sparse_categorical_crossentropy: 0.3304 - sparse_categorical_accuracy: 0.8829 - adversarial_loss: 1.1098 - val_loss: 1.6353 - val_sparse_categorical_crossentropy: 1.0668 - val_sparse_categorical_accuracy: 0.6707 - val_adversarial_loss: 2.7507\n",
      "Epoch 79/100\n",
      "297/297 [==============================] - 243s 817ms/step - loss: 0.5511 - sparse_categorical_crossentropy: 0.3268 - sparse_categorical_accuracy: 0.8795 - adversarial_loss: 1.1196 - val_loss: 1.7642 - val_sparse_categorical_crossentropy: 1.1739 - val_sparse_categorical_accuracy: 0.6530 - val_adversarial_loss: 2.8523\n",
      "Epoch 80/100\n",
      "297/297 [==============================] - 237s 797ms/step - loss: 0.5503 - sparse_categorical_crossentropy: 0.3292 - sparse_categorical_accuracy: 0.8808 - adversarial_loss: 1.1084 - val_loss: 1.7089 - val_sparse_categorical_crossentropy: 1.1342 - val_sparse_categorical_accuracy: 0.6625 - val_adversarial_loss: 2.7771\n",
      "Epoch 81/100\n",
      "297/297 [==============================] - 243s 819ms/step - loss: 0.5426 - sparse_categorical_crossentropy: 0.3238 - sparse_categorical_accuracy: 0.8837 - adversarial_loss: 1.0942 - val_loss: 1.6368 - val_sparse_categorical_crossentropy: 1.0765 - val_sparse_categorical_accuracy: 0.6662 - val_adversarial_loss: 2.7092\n",
      "Epoch 82/100\n",
      "297/297 [==============================] - 276s 929ms/step - loss: 0.5379 - sparse_categorical_crossentropy: 0.3219 - sparse_categorical_accuracy: 0.8845 - adversarial_loss: 1.0781 - val_loss: 1.6346 - val_sparse_categorical_crossentropy: 1.0753 - val_sparse_categorical_accuracy: 0.6656 - val_adversarial_loss: 2.7043\n",
      "Epoch 83/100\n",
      "297/297 [==============================] - 252s 847ms/step - loss: 0.5291 - sparse_categorical_crossentropy: 0.3143 - sparse_categorical_accuracy: 0.8855 - adversarial_loss: 1.0715 - val_loss: 1.6432 - val_sparse_categorical_crossentropy: 1.0760 - val_sparse_categorical_accuracy: 0.6669 - val_adversarial_loss: 2.7438\n",
      "Epoch 84/100\n",
      "297/297 [==============================] - 247s 832ms/step - loss: 0.5525 - sparse_categorical_crossentropy: 0.3295 - sparse_categorical_accuracy: 0.8819 - adversarial_loss: 1.1138 - val_loss: 1.5922 - val_sparse_categorical_crossentropy: 1.0466 - val_sparse_categorical_accuracy: 0.6814 - val_adversarial_loss: 2.6387\n",
      "Epoch 85/100\n",
      "297/297 [==============================] - 241s 810ms/step - loss: 0.5160 - sparse_categorical_crossentropy: 0.3057 - sparse_categorical_accuracy: 0.8914 - adversarial_loss: 1.0538 - val_loss: 1.5492 - val_sparse_categorical_crossentropy: 1.0212 - val_sparse_categorical_accuracy: 0.6852 - val_adversarial_loss: 2.5528\n",
      "Epoch 86/100\n",
      "297/297 [==============================] - 250s 842ms/step - loss: 0.5315 - sparse_categorical_crossentropy: 0.3170 - sparse_categorical_accuracy: 0.8855 - adversarial_loss: 1.0701 - val_loss: 1.5715 - val_sparse_categorical_crossentropy: 1.0252 - val_sparse_categorical_accuracy: 0.6884 - val_adversarial_loss: 2.6431\n",
      "Epoch 87/100\n",
      "297/297 [==============================] - 259s 871ms/step - loss: 0.5050 - sparse_categorical_crossentropy: 0.2924 - sparse_categorical_accuracy: 0.8929 - adversarial_loss: 1.0617 - val_loss: 1.6346 - val_sparse_categorical_crossentropy: 1.0719 - val_sparse_categorical_accuracy: 0.6713 - val_adversarial_loss: 2.7214\n",
      "Epoch 88/100\n",
      "297/297 [==============================] - 267s 898ms/step - loss: 0.5269 - sparse_categorical_crossentropy: 0.3134 - sparse_categorical_accuracy: 0.8879 - adversarial_loss: 1.0655 - val_loss: 1.5797 - val_sparse_categorical_crossentropy: 1.0417 - val_sparse_categorical_accuracy: 0.6808 - val_adversarial_loss: 2.6013\n",
      "Epoch 89/100\n",
      "297/297 [==============================] - 253s 852ms/step - loss: 0.5153 - sparse_categorical_crossentropy: 0.3050 - sparse_categorical_accuracy: 0.8885 - adversarial_loss: 1.0527 - val_loss: 1.5791 - val_sparse_categorical_crossentropy: 1.0299 - val_sparse_categorical_accuracy: 0.6738 - val_adversarial_loss: 2.6569\n",
      "Epoch 90/100\n",
      "297/297 [==============================] - 256s 861ms/step - loss: 0.5261 - sparse_categorical_crossentropy: 0.3123 - sparse_categorical_accuracy: 0.8871 - adversarial_loss: 1.0665 - val_loss: 1.5754 - val_sparse_categorical_crossentropy: 1.0351 - val_sparse_categorical_accuracy: 0.6783 - val_adversarial_loss: 2.6129\n",
      "Epoch 91/100\n",
      "297/297 [==============================] - 240s 807ms/step - loss: 0.5070 - sparse_categorical_crossentropy: 0.2949 - sparse_categorical_accuracy: 0.8930 - adversarial_loss: 1.0605 - val_loss: 1.7265 - val_sparse_categorical_crossentropy: 1.1477 - val_sparse_categorical_accuracy: 0.6593 - val_adversarial_loss: 2.7970\n",
      "Epoch 92/100\n",
      "297/297 [==============================] - 240s 808ms/step - loss: 0.5030 - sparse_categorical_crossentropy: 0.2938 - sparse_categorical_accuracy: 0.8920 - adversarial_loss: 1.0478 - val_loss: 1.6007 - val_sparse_categorical_crossentropy: 1.0626 - val_sparse_categorical_accuracy: 0.6732 - val_adversarial_loss: 2.6007\n",
      "Epoch 93/100\n",
      "297/297 [==============================] - 242s 816ms/step - loss: 0.4926 - sparse_categorical_crossentropy: 0.2831 - sparse_categorical_accuracy: 0.8992 - adversarial_loss: 1.0496 - val_loss: 1.6099 - val_sparse_categorical_crossentropy: 1.0540 - val_sparse_categorical_accuracy: 0.6814 - val_adversarial_loss: 2.6890\n",
      "Epoch 94/100\n",
      "297/297 [==============================] - 258s 867ms/step - loss: 0.5093 - sparse_categorical_crossentropy: 0.2988 - sparse_categorical_accuracy: 0.8907 - adversarial_loss: 1.0528 - val_loss: 1.6670 - val_sparse_categorical_crossentropy: 1.1039 - val_sparse_categorical_accuracy: 0.6694 - val_adversarial_loss: 2.7217\n",
      "Epoch 95/100\n",
      "297/297 [==============================] - 261s 880ms/step - loss: 0.5072 - sparse_categorical_crossentropy: 0.2969 - sparse_categorical_accuracy: 0.8918 - adversarial_loss: 1.0533 - val_loss: 1.7170 - val_sparse_categorical_crossentropy: 1.1483 - val_sparse_categorical_accuracy: 0.6587 - val_adversarial_loss: 2.7465\n",
      "Epoch 96/100\n",
      "297/297 [==============================] - 268s 904ms/step - loss: 0.4819 - sparse_categorical_crossentropy: 0.2783 - sparse_categorical_accuracy: 0.9011 - adversarial_loss: 1.0153 - val_loss: 1.7591 - val_sparse_categorical_crossentropy: 1.1652 - val_sparse_categorical_accuracy: 0.6713 - val_adversarial_loss: 2.8705\n",
      "Epoch 97/100\n",
      "297/297 [==============================] - 244s 822ms/step - loss: 0.4729 - sparse_categorical_crossentropy: 0.2671 - sparse_categorical_accuracy: 0.9038 - adversarial_loss: 1.0265 - val_loss: 1.7292 - val_sparse_categorical_crossentropy: 1.1416 - val_sparse_categorical_accuracy: 0.6681 - val_adversarial_loss: 2.8408\n",
      "Epoch 98/100\n",
      "297/297 [==============================] - 282s 951ms/step - loss: 0.4772 - sparse_categorical_crossentropy: 0.2767 - sparse_categorical_accuracy: 0.9013 - adversarial_loss: 1.0022 - val_loss: 1.6380 - val_sparse_categorical_crossentropy: 1.0793 - val_sparse_categorical_accuracy: 0.6694 - val_adversarial_loss: 2.7015\n",
      "Epoch 99/100\n",
      "297/297 [==============================] - 260s 876ms/step - loss: 0.4672 - sparse_categorical_crossentropy: 0.2653 - sparse_categorical_accuracy: 0.9084 - adversarial_loss: 1.0083 - val_loss: 1.6767 - val_sparse_categorical_crossentropy: 1.1048 - val_sparse_categorical_accuracy: 0.6593 - val_adversarial_loss: 2.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "297/297 [==============================] - 255s 859ms/step - loss: 0.4692 - sparse_categorical_crossentropy: 0.2665 - sparse_categorical_accuracy: 0.9061 - adversarial_loss: 1.0111 - val_loss: 1.6086 - val_sparse_categorical_crossentropy: 1.0461 - val_sparse_categorical_accuracy: 0.6700 - val_adversarial_loss: 2.7216\n",
      "2.0.0\n",
      "1582\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 1.4505 - sparse_categorical_crossentropy: 0.9517 - sparse_categorical_accuracy: 0.6947 - adversarial_loss: 2.4937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4504812788963317, 0.95174, 0.6946903, 2.493707]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  breakhistf2v026-nsl-v4-02.ipynb  v1.0.0 \n",
    "# \n",
    "#  --------------------------------------------------\n",
    "#  Hangzhou Domain Zones Technology Co., Ltd\n",
    "\n",
    "#  Apache Licence 2.0       https://www.apache.org/licenses/LICENSE-2.0\n",
    "#  --------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import neural_structured_learning as nsl\n",
    "from tensorflow.python.keras.api._v2.keras import layers, optimizers, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import random\n",
    "\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "IMAGE_INPUT_NAME = 'images'\n",
    "LABEL_INPUT_NAME = 'labels'\n",
    "  \n",
    "%matplotlib inline\n",
    " \n",
    "def read_csv(csvnamepath, filename, is2=False):\n",
    "     \n",
    "\n",
    "    # read from csv file\n",
    "    images, labels = [], []\n",
    "    benigns = [\"adenosis\" ,\"fibroadenoma\" ,\"tubular_adenoma\" , \"phyllodes_tumor\"]\n",
    "    with open(os.path.join(csvnamepath, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label, cancername = row\n",
    "            if is2:\n",
    "                if  cancername in benigns:\n",
    "                    label = 0\n",
    "                else:\n",
    "                    label = 1\n",
    "            else:\n",
    "                label = int(label)\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "@tf.function \n",
    "def load_breakhis(dirc, filename, is2 = False , mode='train' ):\n",
    "    classdir2label={}\n",
    "     \n",
    "    filedirs = os.listdir( dirc)\n",
    "    for filedir in filedirs:\n",
    "        if not os.path.isdir(os.path.join(dirc,filedir)):\n",
    "            continue\n",
    "        classdir2label[filedir]=len(classdir2label.keys())\n",
    "    \n",
    "\n",
    "     \n",
    "    images, labels = read_csv(os.path.join(os.path.abspath('.'),'tf2breakhis'), filename ,is2)  \n",
    "    if mode == 'train':  # 60%\n",
    "        images = images[:int(0.6 * len(images))]\n",
    "        labels = labels[:int(0.6 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # 20% = 80%->100%\n",
    "        images = images[int(0.8 * len(images)):]\n",
    "        labels = labels[int(0.8 * len(labels)):]\n",
    "    return images, labels, classdir2label\n",
    " \n",
    "img_mean = tf.constant([0.485, 0.456, 0.406])\n",
    "img_std = tf.constant([0.229, 0.224, 0.225])\n",
    "\n",
    "@tf.function\n",
    "def normalize(x, mean=img_mean, std=img_std):\n",
    "    # x shape: [224, 224, 3]\n",
    "    # mean：shape为1；这里用到了广播机制。我们安装好右边对齐的原则，可以得到如下；\n",
    "    # mean : [1, 1, 3], std: [3]        先插入1\n",
    "    # mean : [224, 224, 3], std: [3]    再变为224\n",
    "    x = (x - mean)/std\n",
    "    return x\n",
    "\n",
    "# 数据normalize之后，这里有一个反normalizaion操作。比如数据可视化的时候，需要反过来。\n",
    "# @tf.function\n",
    "def denormalize(x, mean=img_mean, std=img_std):\n",
    "    x = x * std + mean\n",
    "    return x\n",
    "\n",
    "  \n",
    "# @tf.function \n",
    "def preprocess_train_nsl(images,labels):\n",
    "    i =0;\n",
    "    images1= []\n",
    "    labels1= []\n",
    "    imagelen = len(images)\n",
    "    #imagelen = 5\n",
    "    print (tf.__version__)\n",
    "    print (len(images))\n",
    "    while (True):\n",
    "        if i >= imagelen :\n",
    "            break\n",
    "        \n",
    "        x= images[i]\n",
    "        y =labels[i]\n",
    "        x = tf.io.read_file(x)\n",
    "        x = tf.image.decode_jpeg(x, channels=3) # RGBA    \n",
    "        x = tf.image.resize(x, [244, 244])\n",
    "        \n",
    "        x1 = tf.image.random_flip_left_right(x)\n",
    "     \n",
    "        # x = tf.image.random_flip_up_down(x)\n",
    "         \n",
    "        x = tf.image.random_crop(x, [224,224,3])\n",
    "        \n",
    "        x1 = tf.image.random_crop(x1, [224,224,3])\n",
    "        \n",
    "       # x = tf.image.resize_with_crop_or_pad(x, 460,700)\n",
    "        #x = tf.image.random_flip_left_right(x)\n",
    "       #   x = tf.image.random_crop(x, [460,700,3])\n",
    "        x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "        x = normalize(x)\n",
    "        x = tf.convert_to_tensor(x) \n",
    "        \n",
    "        x1 = tf.cast(x1, dtype=tf.float32) / 255.\n",
    "        x1 = normalize(x1)\n",
    "        x1 = tf.convert_to_tensor(x1) \n",
    "        \n",
    "        y = tf.convert_to_tensor(y)\n",
    "        #y = tf.one_hot(y, depth=8)      \n",
    "        images1.append(x)\n",
    "        labels1.append(y)\n",
    "        \n",
    "        images1.append(x1)\n",
    "        labels1.append(y)\n",
    "        \n",
    "        i = i+1 \n",
    "    return images1, labels1\n",
    "\n",
    "\n",
    "def preprocessnsl(images,labels):\n",
    "    i =0;\n",
    "    images1= []\n",
    "    labels1= []\n",
    "    imagelen = len(images)\n",
    "    #imagelen = 5\n",
    "    print (tf.__version__)\n",
    "    print (len(images))\n",
    "    while (True):\n",
    "        if i >= imagelen :\n",
    "            break\n",
    "        \n",
    "        x= images[i]\n",
    "        y =labels[i]\n",
    "        x = tf.io.read_file(x)\n",
    "        x = tf.image.decode_jpeg(x, channels=3) # RGBA    \n",
    "        x = tf.image.resize(x, [244, 244])\n",
    "   \n",
    "        x = tf.image.random_crop(x, [224,224,3])\n",
    "       # x = tf.image.resize_with_crop_or_pad(x, 460,700)\n",
    "        #x = tf.image.random_flip_left_right(x)\n",
    "       #   x = tf.image.random_crop(x, [460,700,3])\n",
    "        x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "        x = normalize(x)\n",
    "        x = tf.convert_to_tensor(x) \n",
    "        y = tf.convert_to_tensor(y)\n",
    "        #y = tf.one_hot(y, depth=8)      \n",
    "        images1.append(x)\n",
    "        labels1.append(y)\n",
    "        i = i+1 \n",
    "    return images1, labels1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_tensor(images,labels):\n",
    "    timages1 = tf.convert_to_tensor(images)\n",
    "    #timages1.reshape(imagelen,2224,224,3) \n",
    "    tlabels1 = tf.convert_to_tensor(labels) \n",
    "    #tlabels1 = tf.one_hot(tlabels1, depth=8)\n",
    "    return timages1, tlabels1\n",
    "\n",
    " \n",
    "def shuffletwolists(list1,list2,shufflesize):\n",
    "    temp = list(zip(list1, list2))\n",
    "    i =0\n",
    "    while(True):\n",
    "        if i > shufflesize:\n",
    "            break  \n",
    "        random.shuffle(temp)\n",
    "        i = i+1\n",
    "    \n",
    "    res1 ,res2 =zip(*temp)\n",
    "    return list(res1), list(res2)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function \n",
    "def convert_to_dictionaries(image, label):\n",
    "    return {'images':image, 'labels':label}\n",
    "\n",
    " \n",
    "  \n",
    "  \n",
    "\n",
    "batch_size = 32\n",
    " \n",
    "    \n",
    "images, labels, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'),  \"tf2breakhisnewCSV\",False,'train')\n",
    "\n",
    "\n",
    "(images , labels)  =shuffletwolists( images ,labels ,1000)  \n",
    "\n",
    "(x_train , y_train)  = preprocess_train_nsl(images ,labels ) \n",
    "\n",
    " \n",
    "(x_train , y_train)  =shuffletwolists( x_train ,y_train ,1000)\n",
    "\n",
    "  \n",
    "images2, labels2, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'),  \"tf2breakhisnewCSV\",False,'val')\n",
    "val_steps =  len(images2) / batch_size\n",
    "\n",
    " \n",
    "\n",
    "(x_val , y_val)  = preprocessnsl(images2 ,labels2 ) \n",
    "\n",
    "(x_val , y_val)  =shuffletwolists( x_val ,y_val ,1000 ) \n",
    " \n",
    "\n",
    "db_train = tf.data.Dataset.from_tensor_slices({'feature':x_train, 'label':y_train}).batch(batch_size)\n",
    " \n",
    "db_val =  tf.data.Dataset.from_tensor_slices({'feature':x_val, 'label':y_val}).batch(batch_size)\n",
    "\n",
    "  \n",
    "\n",
    "resnetdense = keras.Sequential([\n",
    "\n",
    "    tf.keras.Input((224, 224,3), name='feature'),\n",
    "    #tf.keras.Input((460, 700,3), name='feature'),\n",
    "    \n",
    "    #tf.keras.Input((456, 692,3), name='feature'),\n",
    " \n",
    "    \n",
    "    tf.keras.layers.Conv2D(16,5,3 , activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(3,3),\n",
    "    #tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(64,5,3, activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    #tf.keras.layers.ReLU(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "   \n",
    "    #tf.keras.layers.Dense(128), \n",
    "    \n",
    "    tf.keras.layers.Dense(128,activation=tf.nn.sigmoid ), \n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),  \n",
    "    #tf.keras.layers.ReLU(),\n",
    "    #tf.keras.layers.Dense(8)\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.softmax)\n",
    "   ])\n",
    "\n",
    "\n",
    " \n",
    "  \n",
    "\n",
    "LOGDIR='log/breakhistf2v026-nsl-v4-02' \n",
    "  \n",
    "adv_grad_norm = 'infinity'\n",
    "\n",
    "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05,adv_grad_norm = adv_grad_norm)\n",
    "adv_model = nsl.keras.AdversarialRegularization(resnetdense, adv_config=adv_config)\n",
    " \n",
    "adv_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "adv_model.fit(db_train,  validation_data=  db_val , validation_steps = val_steps, epochs=100, verbose =1)\n",
    "\n",
    "images3, labels3, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'),  \"tf2breakhisnewCSV\",False,'test')\n",
    "\n",
    "\n",
    "(x_test , y_test)  = preprocessnsl(images3 ,labels3 ) \n",
    "db_test =  tf.data.Dataset.from_tensor_slices({'feature':x_test, 'label':y_test}).batch(batch_size)\n",
    " \n",
    "adv_model.evaluate( db_test)\n",
    " \n",
    "  \n",
    "\n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
