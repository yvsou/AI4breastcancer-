{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            multiple                  1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  25664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  73856     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  520       \n",
      "=================================================================\n",
      "Total params: 109,512\n",
      "Trainable params: 109,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "297/297 [==============================] - 708s 2s/step - loss: 1.7246 - accuracy: 0.4436 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "297/297 [==============================] - 690s 2s/step - loss: 1.5891 - accuracy: 0.5023 - val_loss: 1.5346 - val_accuracy: 0.5006\n",
      "Epoch 3/100\n",
      "297/297 [==============================] - 1289s 4s/step - loss: 1.5402 - accuracy: 0.5118 - val_loss: 1.4848 - val_accuracy: 0.4997\n",
      "Epoch 4/100\n",
      "297/297 [==============================] - 738s 2s/step - loss: 1.4896 - accuracy: 0.5134 - val_loss: 1.4317 - val_accuracy: 0.5019\n",
      "Epoch 5/100\n",
      "297/297 [==============================] - 730s 2s/step - loss: 1.4498 - accuracy: 0.5155 - val_loss: 1.4063 - val_accuracy: 0.5009\n",
      "Epoch 6/100\n",
      "297/297 [==============================] - 672s 2s/step - loss: 1.4189 - accuracy: 0.5178 - val_loss: 1.3804 - val_accuracy: 0.5250\n",
      "Epoch 7/100\n",
      "297/297 [==============================] - 666s 2s/step - loss: 1.3941 - accuracy: 0.5246 - val_loss: 1.3591 - val_accuracy: 0.5326\n",
      "Epoch 8/100\n",
      "297/297 [==============================] - 669s 2s/step - loss: 1.3846 - accuracy: 0.5236 - val_loss: 1.3397 - val_accuracy: 0.5234\n",
      "Epoch 9/100\n",
      "297/297 [==============================] - 666s 2s/step - loss: 1.3619 - accuracy: 0.5323 - val_loss: 1.3276 - val_accuracy: 0.5288\n",
      "Epoch 10/100\n",
      "297/297 [==============================] - 664s 2s/step - loss: 1.3536 - accuracy: 0.5315 - val_loss: 1.3162 - val_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "297/297 [==============================] - 698s 2s/step - loss: 1.3449 - accuracy: 0.5357 - val_loss: 1.3008 - val_accuracy: 0.5322\n",
      "Epoch 12/100\n",
      "297/297 [==============================] - 722s 2s/step - loss: 1.3322 - accuracy: 0.5357 - val_loss: 1.2948 - val_accuracy: 0.5291\n",
      "Epoch 13/100\n",
      "297/297 [==============================] - 719s 2s/step - loss: 1.3281 - accuracy: 0.5354 - val_loss: 1.3076 - val_accuracy: 0.5231\n",
      "Epoch 14/100\n",
      "297/297 [==============================] - 721s 2s/step - loss: 1.3245 - accuracy: 0.5397 - val_loss: 1.3067 - val_accuracy: 0.5310\n",
      "Epoch 15/100\n",
      "297/297 [==============================] - 720s 2s/step - loss: 1.3107 - accuracy: 0.5405 - val_loss: 1.2933 - val_accuracy: 0.5417\n",
      "Epoch 16/100\n",
      "297/297 [==============================] - 721s 2s/step - loss: 1.3026 - accuracy: 0.5473 - val_loss: 1.2696 - val_accuracy: 0.5452\n",
      "Epoch 17/100\n",
      "297/297 [==============================] - 717s 2s/step - loss: 1.2978 - accuracy: 0.5462 - val_loss: 1.2946 - val_accuracy: 0.5345\n",
      "Epoch 18/100\n",
      "297/297 [==============================] - 724s 2s/step - loss: 1.2937 - accuracy: 0.5435 - val_loss: 1.2631 - val_accuracy: 0.5338\n",
      "Epoch 19/100\n",
      "297/297 [==============================] - 720s 2s/step - loss: 1.2807 - accuracy: 0.5469 - val_loss: 1.2464 - val_accuracy: 0.5430\n",
      "Epoch 20/100\n",
      "297/297 [==============================] - 721s 2s/step - loss: 1.2695 - accuracy: 0.5517 - val_loss: 1.2390 - val_accuracy: 0.5534\n",
      "Epoch 21/100\n",
      "297/297 [==============================] - 714s 2s/step - loss: 1.2574 - accuracy: 0.5521 - val_loss: 1.2430 - val_accuracy: 0.5629\n",
      "Epoch 22/100\n",
      "297/297 [==============================] - 663s 2s/step - loss: 1.2563 - accuracy: 0.5560 - val_loss: 1.2265 - val_accuracy: 0.5471\n",
      "Epoch 23/100\n",
      "297/297 [==============================] - 660s 2s/step - loss: 1.2489 - accuracy: 0.5562 - val_loss: 1.2423 - val_accuracy: 0.5449\n",
      "Epoch 24/100\n",
      "297/297 [==============================] - 660s 2s/step - loss: 1.2329 - accuracy: 0.5655 - val_loss: 1.2213 - val_accuracy: 0.5762\n",
      "Epoch 25/100\n",
      "297/297 [==============================] - 661s 2s/step - loss: 1.2307 - accuracy: 0.5673 - val_loss: 1.2149 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "297/297 [==============================] - 661s 2s/step - loss: 1.2124 - accuracy: 0.5723 - val_loss: 1.2034 - val_accuracy: 0.5774\n",
      "Epoch 27/100\n",
      "297/297 [==============================] - 690s 2s/step - loss: 1.2044 - accuracy: 0.5728 - val_loss: 1.1907 - val_accuracy: 0.5815\n",
      "Epoch 28/100\n",
      "297/297 [==============================] - 713s 2s/step - loss: 1.1939 - accuracy: 0.5759 - val_loss: 1.1775 - val_accuracy: 0.5815\n",
      "Epoch 29/100\n",
      "297/297 [==============================] - 711s 2s/step - loss: 1.1837 - accuracy: 0.5791 - val_loss: 1.1748 - val_accuracy: 0.5806\n",
      "Epoch 30/100\n",
      "297/297 [==============================] - 714s 2s/step - loss: 1.1753 - accuracy: 0.5850 - val_loss: 1.1578 - val_accuracy: 0.5888\n",
      "Epoch 31/100\n",
      "297/297 [==============================] - 717s 2s/step - loss: 1.1676 - accuracy: 0.5867 - val_loss: 1.1421 - val_accuracy: 0.6049\n",
      "Epoch 32/100\n",
      "297/297 [==============================] - 715s 2s/step - loss: 1.1608 - accuracy: 0.5885 - val_loss: 1.1463 - val_accuracy: 0.5901\n",
      "Epoch 33/100\n",
      "297/297 [==============================] - 716s 2s/step - loss: 1.1425 - accuracy: 0.5975 - val_loss: 1.1617 - val_accuracy: 0.5879\n",
      "Epoch 34/100\n",
      "297/297 [==============================] - 716s 2s/step - loss: 1.1432 - accuracy: 0.5916 - val_loss: 1.1407 - val_accuracy: 0.5917\n",
      "Epoch 35/100\n",
      "297/297 [==============================] - 713s 2s/step - loss: 1.1368 - accuracy: 0.5987 - val_loss: 1.1404 - val_accuracy: 0.5926\n",
      "Epoch 36/100\n",
      "297/297 [==============================] - 716s 2s/step - loss: 1.1376 - accuracy: 0.5932 - val_loss: 1.1247 - val_accuracy: 0.5939\n",
      "Epoch 37/100\n",
      "297/297 [==============================] - 715s 2s/step - loss: 1.1245 - accuracy: 0.5978 - val_loss: 1.1181 - val_accuracy: 0.5942\n",
      "Epoch 38/100\n",
      "297/297 [==============================] - 671s 2s/step - loss: 1.1120 - accuracy: 0.6021 - val_loss: 1.1111 - val_accuracy: 0.6040\n",
      "Epoch 39/100\n",
      "297/297 [==============================] - 663s 2s/step - loss: 1.0974 - accuracy: 0.6100 - val_loss: 1.1097 - val_accuracy: 0.5980\n",
      "Epoch 40/100\n",
      "297/297 [==============================] - 663s 2s/step - loss: 1.1025 - accuracy: 0.6061 - val_loss: 1.0940 - val_accuracy: 0.6065\n",
      "Epoch 41/100\n",
      "297/297 [==============================] - 661s 2s/step - loss: 1.0849 - accuracy: 0.6092 - val_loss: 1.0890 - val_accuracy: 0.6081\n",
      "Epoch 42/100\n",
      "297/297 [==============================] - 664s 2s/step - loss: 1.0859 - accuracy: 0.6138 - val_loss: 1.0827 - val_accuracy: 0.6116\n",
      "Epoch 43/100\n",
      "297/297 [==============================] - 687s 2s/step - loss: 1.0710 - accuracy: 0.6133 - val_loss: 1.0838 - val_accuracy: 0.6075\n",
      "Epoch 44/100\n",
      "297/297 [==============================] - 713s 2s/step - loss: 1.0687 - accuracy: 0.6156 - val_loss: 1.0892 - val_accuracy: 0.6030\n",
      "Epoch 45/100\n",
      "297/297 [==============================] - 714s 2s/step - loss: 1.0606 - accuracy: 0.6105 - val_loss: 1.0693 - val_accuracy: 0.6043\n",
      "Epoch 46/100\n",
      "297/297 [==============================] - 714s 2s/step - loss: 1.0481 - accuracy: 0.6149 - val_loss: 1.0864 - val_accuracy: 0.6097\n",
      "Epoch 47/100\n",
      "297/297 [==============================] - 690s 2s/step - loss: 1.0513 - accuracy: 0.6142 - val_loss: 1.0843 - val_accuracy: 0.6094\n",
      "Epoch 48/100\n",
      "297/297 [==============================] - 666s 2s/step - loss: 1.0315 - accuracy: 0.6217 - val_loss: 1.0608 - val_accuracy: 0.6106\n",
      "Epoch 49/100\n",
      "297/297 [==============================] - 667s 2s/step - loss: 1.0310 - accuracy: 0.6257 - val_loss: 1.0720 - val_accuracy: 0.6094\n",
      "Epoch 50/100\n",
      "297/297 [==============================] - 663s 2s/step - loss: 1.0274 - accuracy: 0.6232 - val_loss: 1.1125 - val_accuracy: 0.5970\n",
      "Epoch 51/100\n",
      "297/297 [==============================] - 663s 2s/step - loss: 1.0141 - accuracy: 0.6273 - val_loss: 1.0527 - val_accuracy: 0.6185\n",
      "Epoch 52/100\n",
      "297/297 [==============================] - 664s 2s/step - loss: 1.0023 - accuracy: 0.6346 - val_loss: 1.0322 - val_accuracy: 0.6233\n",
      "Epoch 53/100\n",
      "297/297 [==============================] - 664s 2s/step - loss: 0.9910 - accuracy: 0.6328 - val_loss: 1.0633 - val_accuracy: 0.6075\n",
      "Epoch 54/100\n",
      "297/297 [==============================] - 707s 2s/step - loss: 0.9905 - accuracy: 0.6379 - val_loss: 1.0593 - val_accuracy: 0.6128\n",
      "Epoch 55/100\n",
      "297/297 [==============================] - 725s 2s/step - loss: 0.9871 - accuracy: 0.6301 - val_loss: 1.0236 - val_accuracy: 0.6283\n",
      "Epoch 56/100\n",
      "297/297 [==============================] - 722s 2s/step - loss: 0.9724 - accuracy: 0.6395 - val_loss: 1.0216 - val_accuracy: 0.6192\n",
      "Epoch 57/100\n",
      "297/297 [==============================] - 718s 2s/step - loss: 0.9668 - accuracy: 0.6460 - val_loss: 1.0171 - val_accuracy: 0.6242\n",
      "Epoch 58/100\n",
      "297/297 [==============================] - 729s 2s/step - loss: 0.9530 - accuracy: 0.6438 - val_loss: 1.0130 - val_accuracy: 0.6233\n",
      "Epoch 59/100\n",
      "297/297 [==============================] - 689s 2s/step - loss: 0.9488 - accuracy: 0.6483 - val_loss: 1.0484 - val_accuracy: 0.6176\n",
      "Epoch 60/100\n",
      "297/297 [==============================] - 685s 2s/step - loss: 0.9543 - accuracy: 0.6482 - val_loss: 1.0075 - val_accuracy: 0.6242\n",
      "Epoch 61/100\n",
      "297/297 [==============================] - 684s 2s/step - loss: 0.9444 - accuracy: 0.6491 - val_loss: 1.0041 - val_accuracy: 0.6286\n",
      "Epoch 62/100\n",
      "297/297 [==============================] - 683s 2s/step - loss: 0.9351 - accuracy: 0.6547 - val_loss: 0.9979 - val_accuracy: 0.6312\n",
      "Epoch 63/100\n",
      "297/297 [==============================] - 685s 2s/step - loss: 0.9261 - accuracy: 0.6571 - val_loss: 1.0417 - val_accuracy: 0.6226\n",
      "Epoch 64/100\n",
      "297/297 [==============================] - 701s 2s/step - loss: 0.9198 - accuracy: 0.6571 - val_loss: 0.9924 - val_accuracy: 0.6350\n",
      "Epoch 65/100\n",
      "297/297 [==============================] - 741s 2s/step - loss: 0.9020 - accuracy: 0.6659 - val_loss: 1.0120 - val_accuracy: 0.6324\n",
      "Epoch 66/100\n",
      "297/297 [==============================] - 738s 2s/step - loss: 0.9077 - accuracy: 0.6623 - val_loss: 0.9786 - val_accuracy: 0.6353\n",
      "Epoch 67/100\n",
      "297/297 [==============================] - 737s 2s/step - loss: 0.9035 - accuracy: 0.6649 - val_loss: 1.0109 - val_accuracy: 0.6233\n",
      "Epoch 68/100\n",
      "297/297 [==============================] - 738s 2s/step - loss: 0.8901 - accuracy: 0.6698 - val_loss: 0.9988 - val_accuracy: 0.6229\n",
      "Epoch 69/100\n",
      "297/297 [==============================] - 741s 2s/step - loss: 0.8885 - accuracy: 0.6734 - val_loss: 1.0134 - val_accuracy: 0.6299\n",
      "Epoch 70/100\n",
      "297/297 [==============================] - 739s 2s/step - loss: 0.8732 - accuracy: 0.6788 - val_loss: 0.9721 - val_accuracy: 0.6403\n",
      "Epoch 71/100\n",
      "297/297 [==============================] - 742s 2s/step - loss: 0.8682 - accuracy: 0.6772 - val_loss: 0.9635 - val_accuracy: 0.6435\n",
      "Epoch 72/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.8617 - accuracy: 0.6817 - val_loss: 0.9655 - val_accuracy: 0.6410\n",
      "Epoch 73/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.8527 - accuracy: 0.6828 - val_loss: 0.9626 - val_accuracy: 0.6413\n",
      "Epoch 74/100\n",
      "297/297 [==============================] - 733s 2s/step - loss: 0.8554 - accuracy: 0.6818 - val_loss: 0.9482 - val_accuracy: 0.6463\n",
      "Epoch 75/100\n",
      "297/297 [==============================] - 738s 2s/step - loss: 0.8486 - accuracy: 0.6819 - val_loss: 0.9540 - val_accuracy: 0.6429\n",
      "Epoch 76/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.8381 - accuracy: 0.6834 - val_loss: 0.9434 - val_accuracy: 0.6530\n",
      "Epoch 77/100\n",
      "297/297 [==============================] - 744s 3s/step - loss: 0.8260 - accuracy: 0.6938 - val_loss: 1.0021 - val_accuracy: 0.6239\n",
      "Epoch 78/100\n",
      "297/297 [==============================] - 741s 2s/step - loss: 0.8250 - accuracy: 0.6957 - val_loss: 0.9923 - val_accuracy: 0.6473\n",
      "Epoch 79/100\n",
      "297/297 [==============================] - 736s 2s/step - loss: 0.8176 - accuracy: 0.6962 - val_loss: 0.9687 - val_accuracy: 0.6381\n",
      "Epoch 80/100\n",
      "297/297 [==============================] - 739s 2s/step - loss: 0.8128 - accuracy: 0.6992 - val_loss: 0.9550 - val_accuracy: 0.6530\n",
      "Epoch 81/100\n",
      "297/297 [==============================] - 739s 2s/step - loss: 0.7988 - accuracy: 0.7013 - val_loss: 0.9481 - val_accuracy: 0.6444\n",
      "Epoch 82/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.7987 - accuracy: 0.7023 - val_loss: 0.9664 - val_accuracy: 0.6394\n",
      "Epoch 83/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.7854 - accuracy: 0.7070 - val_loss: 0.9420 - val_accuracy: 0.6473\n",
      "Epoch 84/100\n",
      "297/297 [==============================] - 742s 2s/step - loss: 0.7986 - accuracy: 0.7032 - val_loss: 0.9874 - val_accuracy: 0.6406\n",
      "Epoch 85/100\n",
      "297/297 [==============================] - 685s 2s/step - loss: 0.7746 - accuracy: 0.7129 - val_loss: 0.9839 - val_accuracy: 0.6400\n",
      "Epoch 86/100\n",
      "297/297 [==============================] - 684s 2s/step - loss: 0.7762 - accuracy: 0.7105 - val_loss: 0.9553 - val_accuracy: 0.6479\n",
      "Epoch 87/100\n",
      "297/297 [==============================] - 684s 2s/step - loss: 0.7687 - accuracy: 0.7151 - val_loss: 0.9621 - val_accuracy: 0.6470\n",
      "Epoch 88/100\n",
      "297/297 [==============================] - 683s 2s/step - loss: 0.7594 - accuracy: 0.7202 - val_loss: 0.9423 - val_accuracy: 0.6501\n",
      "Epoch 89/100\n",
      "297/297 [==============================] - 684s 2s/step - loss: 0.7581 - accuracy: 0.7148 - val_loss: 0.9719 - val_accuracy: 0.6457\n",
      "Epoch 90/100\n",
      "297/297 [==============================] - 687s 2s/step - loss: 0.7489 - accuracy: 0.7260 - val_loss: 0.9368 - val_accuracy: 0.6514\n",
      "Epoch 91/100\n",
      "297/297 [==============================] - 683s 2s/step - loss: 0.7459 - accuracy: 0.7222 - val_loss: 0.9608 - val_accuracy: 0.6564\n",
      "Epoch 92/100\n",
      "297/297 [==============================] - 684s 2s/step - loss: 0.7487 - accuracy: 0.7235 - val_loss: 0.9659 - val_accuracy: 0.6444\n",
      "Epoch 93/100\n",
      "297/297 [==============================] - 683s 2s/step - loss: 0.7411 - accuracy: 0.7241 - val_loss: 0.9838 - val_accuracy: 0.6476\n",
      "Epoch 94/100\n",
      "297/297 [==============================] - 685s 2s/step - loss: 0.7285 - accuracy: 0.7286 - val_loss: 0.9437 - val_accuracy: 0.6590\n",
      "Epoch 95/100\n",
      "297/297 [==============================] - 682s 2s/step - loss: 0.7172 - accuracy: 0.7336 - val_loss: 0.9321 - val_accuracy: 0.6457\n",
      "Epoch 96/100\n",
      "297/297 [==============================] - 740s 2s/step - loss: 0.7124 - accuracy: 0.7389 - val_loss: 0.9414 - val_accuracy: 0.6615\n",
      "Epoch 97/100\n",
      "297/297 [==============================] - 737s 2s/step - loss: 0.7046 - accuracy: 0.7392 - val_loss: 0.9579 - val_accuracy: 0.6523\n",
      "Epoch 98/100\n",
      "297/297 [==============================] - 736s 2s/step - loss: 0.7057 - accuracy: 0.7381 - val_loss: 0.9422 - val_accuracy: 0.6527\n",
      "Epoch 99/100\n",
      "297/297 [==============================] - 738s 2s/step - loss: 0.7025 - accuracy: 0.7387 - val_loss: 0.9185 - val_accuracy: 0.6643\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 745s 3s/step - loss: 0.6993 - accuracy: 0.7367 - val_loss: 1.0103 - val_accuracy: 0.6242\n",
      "50/50 [==============================] - 87s 2s/step - loss: 1.0454 - accuracy: 0.6043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0454127418994903, 0.60429835]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breakhistf2v9.ipynb  v1.0.0 \n",
    "# \n",
    "#  --------------------------------------------------\n",
    "#  Hangzhou Domain Zones Technology Co., Ltd\n",
    "\n",
    "#  Apache Licence 2.0       https://www.apache.org/licenses/LICENSE-2.0\n",
    "#  --------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import neural_structured_learning as nsl\n",
    "from tensorflow.python.keras.api._v2.keras import layers, optimizers, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "  \n",
    "%matplotlib inline\n",
    "\n",
    "def read_csv(csvnamepath, filename):\n",
    "     \n",
    "\n",
    "    # read from csv file\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(csvnamepath, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    " \n",
    "def load_breakhis(dirc, mode='train'):\n",
    "    classdir2label={}\n",
    "    filename=\"tf2breakhisCSV\"\n",
    "    filedirs = os.listdir( dirc)\n",
    "    for filedir in filedirs:\n",
    "        if not os.path.isdir(os.path.join(dirc,filedir)):\n",
    "            continue\n",
    "        classdir2label[filedir]=len(classdir2label.keys())\n",
    "    \n",
    "\n",
    "     \n",
    "    images, labels = read_csv(os.path.join(os.path.abspath('.'),'tf2breakhis'), filename )  \n",
    "    if mode == 'train':  # 60%\n",
    "        images = images[:int(0.6 * len(images))]\n",
    "        labels = labels[:int(0.6 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # 20% = 80%->100%\n",
    "        images = images[int(0.8 * len(images)):]\n",
    "        labels = labels[int(0.8 * len(labels)):]\n",
    "    return images, labels, classdir2label\n",
    " \n",
    " \n",
    "\n",
    "# 预处理的函数，复制过来。\n",
    "@tf.function\n",
    "def preprocess(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "   \n",
    "    x = tf.io.read_file(x)\n",
    "     \n",
    "    x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "    \n",
    "    #x = tf.image.resize(x, [350, 230])\n",
    "    x = tf.image.resize_with_crop_or_pad(x,896,896)   \n",
    "  \n",
    "    x = tf.image.resize(x, [224, 224])\n",
    "    \n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    #plt.imshow(x)\n",
    "  \n",
    "    # x = tf.image.random_flip_up_down(x)\n",
    "    #x = tf.image.random_crop(x, [224,224,3])\n",
    "    #plt.imshow(x)\n",
    "    \n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    # x = normalize(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=8)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# 预处理的函数，复制过来。\n",
    "@tf.function\n",
    "def preprocess1(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "   \n",
    "    x = tf.io.read_file(x)\n",
    "     \n",
    "    x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "    \n",
    "    #x = tf.image.resize(x, [350, 230])\n",
    "    x = tf.image.resize_with_crop_or_pad(x,896,896)   \n",
    "    x = tf.image.resize(x, [224, 224])\n",
    "    # x = tf.image.random_flip_up_down(x)\n",
    "    #x = tf.image.random_crop(x, [224,224,3])\n",
    "      \n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    # x = normalize(x)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=8)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "batchsz = 32\n",
    "epochnum =10\n",
    "# creat train db   一般训练的时候需要shuffle。其它是不需要的。\n",
    "images, labels, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'), 'train')\n",
    "db_train = tf.data.Dataset.from_tensor_slices((images, labels))  # 变成个Dataset对象。\n",
    "db_train = db_train.shuffle(1000).repeat(2).map(preprocess).shuffle(1000).batch(batchsz)  # map函数图片路径变为内容。\n",
    " \n",
    "\n",
    "# crate validation db\n",
    "images2, labels2, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'), 'val')\n",
    "db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))\n",
    "db_val = db_val.shuffle(1000).repeat(2).map(preprocess).shuffle(1000).batch(batchsz)\n",
    "# create test db\n",
    "images3, labels3, table = load_breakhis(os.path.join(os.path.abspath('.'),'tf2breakhis'), 'test')\n",
    "db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))\n",
    "db_test = db_test.map(preprocess1).batch(batchsz)\n",
    "\n",
    " \n",
    "resnetdense = keras.Sequential([\n",
    "    layers.Conv2D(16,5,3),\n",
    "    layers.MaxPool2D(3,3),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(64,5,3),\n",
    "    layers.MaxPool2D(2,2),\n",
    "    layers.ReLU(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    #\n",
    "    layers.Dense(128), \n",
    "    layers.Dropout(rate=0.5),\n",
    "    \n",
    "    \n",
    "    \n",
    "    layers.Dense(64),  \n",
    "    layers.ReLU(),\n",
    "    layers.Dense(8)\n",
    "   ])\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# 首先创建Resnet18\n",
    "# resnet = ResNet(8)\n",
    "\n",
    "resnetdense.build(input_shape=(batchsz, 224, 224, 3))\n",
    "resnetdense.summary()\n",
    "\n",
    "# monitor监听器, 连续5个验证准确率不增加，这个事情触发。\n",
    " \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=100\n",
    "\n",
    ")\n",
    "\n",
    "  \n",
    "\n",
    " \n",
    "# 网络的装配。\n",
    "resnetdense.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "               loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# 完成标准的train，val, test;\n",
    "# 标准的逻辑必须通过db_val挑选模型的参数，就需要提供一个earlystopping技术，\n",
    "\n",
    "LOGDIR='log/breakhistf2v9' \n",
    "resnetdense.fit(db_train, validation_data=db_val, \n",
    "                        validation_freq=1, epochs=100, \n",
    "                        callbacks=[TensorBoard(log_dir=LOGDIR)])   # 1个epoch验证1次。触发了这个事情，提前停止了。\n",
    "resnetdense.evaluate(db_test)\n",
    " \n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
